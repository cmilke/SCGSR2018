\documentclass[paper=a4,fontsize=12pt]{article}
\usepackage{geometry}
\usepackage{url}
\usepackage{enumitem}
\usepackage{hyperref}


\begin{document}

%VBF is important,
%but not easy
%Can be improved with HGTD, but that has its own issues
%all of this can be solved with Machine Learning
\section*{Background}
    Vector Boson Fusion (VBF) is a process of great importance in high energy physics.

    Through a bit of work, an exact measurement of the VBF cross section can be used to determine the Higgs Boson's self coupling parameter. This parameter, in turn, then provides a description of the Higgs Potential Well, a deeply fundamental aspect of our universe that is as yet only barely understood. %FIXME: wrong!!!

    Unfortunately, the VBF process is a particularly challenging one to identify, due to overlap of multiple quark jets on top of one another. However, the complications of the process lend themselves to a solution by machine learning techniques, which are adept are handling complex assortments of data. As an added measure to combat the effects of pileup with ATLAS, VBF identification could also make use of a planned upgrade for ATLAS called the High Granularity Timing Detector (HGTD). The HGTD provides timing information for track vertices, allowing vertices to be distinguished in both space and time. When combined, machine learning techniques and the HGTD could make for a highly efficient method of tagging VBF processes. The overarching goal of this project then, is to develop a machine learning based algorithm designed to identify VBF processes within the ATLAS experiment, which makes use of timing information from the HGTD.



    %This is why VBF is hard
        %two jets produced by key event, but many more present in detector. Need to identify correct jet pair
    %Use directed machine learning technique to solve these problems
        %Instead of training nn to identify vbf generically, train it to identify key aspects of vbf separately 
\section*{Vector Boson Fusion and Machine Learning}
    The VBF process is a particularly challenging one to identify. The primary process needs to be identified by relating a pair of jets. As these jets can overlap with those produced by the Higgs decay, the task of reconstructing and correctly identifying them is already difficult. The primary process is almost never isolated however, and is in most cases accompanied by a large amount of pileup, which makes the task of finding a VBF process much harder. While techiniques to identify VBF events exist, they are not as efficient as they could be, and cannot be easily extended to include new information about the process. However, such a complex pattern is exactly what machine learning techniques are ideal for. 



    %here's how it can help with VBF 
    %but might be tricky to use.
    %Best way to handle it may be ML,
    %hence why it's perfect for use with VBF NN. 
\section*{High Granularity Timing Detector}
    The High Granularity Timing Detector (HGTD) is a module planned for installation in ATLAS during the Phase-II upgrade. Its primary purpose is to provide precision (30 ps resolution) timing information of tracks tagged within ATLAS. Such timing information is critical in the context of VBF searches within ATLAS, where pileup results in several particles having vertices that partially or completely overlap each other. Currently, it is very difficult to associate seperate tracks with vertices that overlap in space. With the addition of the HGTD though, overlapping vertices will be distinguishable by their time-stamp, making them much easier to associate with the correct track. 
    
    One noteable issue with the HGTD is the prescence of material between itself and the tracker. This material causes scattering of particles entering the HGTD, and can lead to difficulty in determining which vertex in the HGTD should go to which vertices in the tracker. Once again, machine learning techniques may provide the best way to resolve this issue. Herein lies the advantage of combining research in VBF tagging with research on the HGTD. Using machine learning techniques to approach VBF tagging is by itself a worthwhile endevour. Using information from the HGTD to assist in VBF tagging would also be greatly valuable. However, since the HGTD could also benefit from a machine learning algorithm, it only seems appropriate to directly include information from the HGTD into the VBF machine learning algorithm. Doing so would make the best possible use of the HGTD's capabilities, and in doing so would significantly bolster the efficiency of the VBF tagging algorithm.



    %SLAC is a center for machine learning research, with many experts in the field
    %slac has powerful computing resources, which would be valuable in these studies
    %HGTD and VBF synergize well as projects
    %HGTD is great for VBF study, and VBF is a great testing ground for using HGTD.
    %SLAC is ideal then b/c they have ALTIROC1, a prototype of HGTD.
    %So I can do ML work on VBF, while getting hands on understanding of what hgtd can do (with actual testing) and how it works.
    %At the same time, I can use my work on the vbf ml algorithm as feedback to steer development of hgtd.
\section*{The Advantage of SLAC}
    SLAC provides the ideal research environment for this particular project for several reasons. First among these is that SLAC is host to some of the top experts in the field of machine learning. The value of working on a machine learning algorithm while surrounded by such a community cannot be overstated. Of course, machine learning requires not only expertise, but also computational power, a resource which SLAC has an abundance of. SLAC possess a vast, growing array of GPU clusters, which are crucial for training machine learning algorithms over large data sets, as would be the case for the algorithm proposed here. Perhaps the most significant advantage SLAC provides over other research instutions for this particular project however, is that SLAC is currently developing a prototype of the HGTD, known as ALTIROC1.

    Having access to a physical prototype of the HGTD would be invaluable to the development of a machine learning algorithm incorporating HGTD information. Instead of having to merely use simulated data, the precence of ALTIROC1 at SLAC would allow for genuine testing data and an assesment of what information from the HGTD would really look like. Furthermore, development of the VBF algorithm could be used to inform the ongoing development of the HGTD. Undoubtedly, situations will arise in which the information ALTIROC1 povides is found to be less than ideal for actual use in identifying physics processes. By using ALTIROC1 data for the development of a VBF algorithm at SLAC, these deficiencies can be identified during development, and passed directly to the HGTD design team.



    %research done here is immediately helpful to vbf studies, but extends beyond them. 
    %the ml techniques used here for two jets for vbf can be used for other physics events, and extended to more complex processes of more jets in the future.
    %This can aid in the development of the hardware of the hgtd,
    %and can act as a proof of concept of how hgtd output can be used via ml algorithms
\section*{Looking Forward}
    The immediate goal of this research project is to develop a machine learning algorithm to identify vector boson fusion events within ATLAS, with the assistance of information from the HGTD. Yet, the effects of this research will extend far beyond VBF studies alone. Using machine learning algorithms to study multi-jet processes is a new and unexplored technique. The work done here with VBF processes could thus be extended to a wide range of additional event types in later work. Additionally, the use of prototype HGTD information in this algorithm, and the assesment of that information, could influence the overall development of the HGTD leading to its installation in Phase-II. This algorithm can act as a testing ground for key features of the HGTD, and issues identified here will benefit any project in the future which utilizes HGTD hardware. And as a final point, not only will this algorithm's development help to steer the HGTD's hardware design, but it also serves as a template for how to use the HGTD's output in software. The most efficient way to use HGTD timing information may very well be through machine learning, and the techniques incorporating the HGTD in this project can be used as an example for any other machine learning project in the future. Overall, while the goal of this project is fairly narrow, the effects of its development are broad and far reaching.

\end{document}
